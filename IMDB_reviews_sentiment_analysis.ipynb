{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzQDwxTJN11t0ZmN9QiycF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gollum-98/Sentiment-analysis-LSTM-Word-Embeddings/blob/master/IMDB_reviews_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRPXu_6mcbzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c6d7995-78ae-4a24-df6a-3e0096ac6191"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh2tACEtkRSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYZH7Ei4kW1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb, info = tfds.load(\"imdb_reviews\",with_info=True,as_supervised=True)\n",
        "train_data, test_data = imdb[\"train\"], imdb[\"test\"]\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "test_sentences= []\n",
        "test_labels = []\n",
        "for s,l in train_data:\n",
        "  training_sentences.append(s.numpy().decode(\"utf8\"))\n",
        "  training_labels.append(l.numpy())\n",
        "for s,l in test_data:\n",
        "  test_sentences.append(s.numpy().decode(\"utf8\"))\n",
        "  test_labels.append(l.numpy())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wp5VaMIk261",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e4bb4a11-2964-4655-cd0c-613ff4f15b9e"
      },
      "source": [
        "print(test_sentences[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.<br /><br />The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.<br /><br />This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFzlJSlAmeV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "training_labels = np.array(training_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxR4630Cwux6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18b39988-f5f8-4ec8-fdb4-411564b63ba5"
      },
      "source": [
        "print(test_labels[:20])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twAtP48UpfEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dI0LRVMp6sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 150\n",
        "vocab_size = 10000\n",
        "emb_dim = 16\n",
        "tokenizer = Tokenizer(num_words=vocab_size,oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "training_seq = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_seq,maxlen=max_length,padding='post')\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_seq,maxlen = max_length,padding='post')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt_2R30KtYXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "89e56c94-f683-48df-ebb1-b6a677574c7b"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(vocab_size,emb_dim,input_length=max_length),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.LSTM(64,return_sequences=True),\n",
        "                                    tf.keras.layers.LSTM(64),\n",
        "                                    tf.keras.layers.Dense(32,activation=\"relu\"),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(16,activation=\"relu\"),\n",
        "                                    #tf.keras.layers.Dropout(0,3),\n",
        "                                    tf.keras.layers.Dense(1,activation = \"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer = \"adam\",metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 150, 16)           160000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150, 16)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 150, 64)           20736     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 216,385\n",
            "Trainable params: 216,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw3NeL3gvQRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3afdccf8-866a-4862-ba11-2ddef581111c"
      },
      "source": [
        "history = model.fit(training_padded,training_labels,epochs=10,validation_data=(test_padded,test_labels),verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 172s 220ms/step - loss: 0.6912 - accuracy: 0.5143 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 192s 245ms/step - loss: 0.6936 - accuracy: 0.4972 - val_loss: 0.6924 - val_accuracy: 0.5004\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 0.6786 - accuracy: 0.5636 - val_loss: 0.6787 - val_accuracy: 0.5596\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 185s 237ms/step - loss: 0.6188 - accuracy: 0.6439 - val_loss: 0.4845 - val_accuracy: 0.7771\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 0.3733 - accuracy: 0.8418 - val_loss: 0.3353 - val_accuracy: 0.8575\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 187s 239ms/step - loss: 0.2622 - accuracy: 0.8972 - val_loss: 0.3211 - val_accuracy: 0.8659\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 186s 238ms/step - loss: 0.2193 - accuracy: 0.9151 - val_loss: 0.3349 - val_accuracy: 0.8666\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 0.1909 - accuracy: 0.9288 - val_loss: 0.4690 - val_accuracy: 0.8174\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 185s 237ms/step - loss: 0.1660 - accuracy: 0.9402 - val_loss: 0.3794 - val_accuracy: 0.8580\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 185s 237ms/step - loss: 0.1462 - accuracy: 0.9484 - val_loss: 0.4020 - val_accuracy: 0.8523\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}